{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465a6aef",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "**Suárez Pérez Juan Pablo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "debe9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas necesarias...\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc791b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(path = './../Text_Extraction/EXCELSIOR_100_files/'):\n",
    "    # Obtenemos el corpus del directorio...\n",
    "    corpus = PlaintextCorpusReader(path, '.*')\n",
    "    file_list = corpus.fileids()\n",
    "    # Juntamos todo el texto de todos los archivos...\n",
    "    all_text = ''\n",
    "    for file in file_list:\n",
    "        with open(path + file, encoding = 'utf-8') as rfile:\n",
    "            text = rfile.read()\n",
    "            all_text += text\n",
    "    # Removemos las etiquetas html...\n",
    "    soup = BeautifulSoup(all_text, 'lxml')\n",
    "    clean_text = soup.get_text()\n",
    "    clean_text = clean_text.lower()\n",
    "    # Tokenizamos el texto...\n",
    "    words = clean_text.split()\n",
    "    alphabetic_words = []\n",
    "    for word in words:\n",
    "        token = []\n",
    "        for character in word:\n",
    "            if re.match(r'^[a-záéíóúñü+$]', character):\n",
    "                token.append(character)\n",
    "        token = ''.join(token)\n",
    "        if token != '':\n",
    "            alphabetic_words.append(token)\n",
    "    # Quitamos las Stop words...\n",
    "    with open('./stopwords_es.txt', encoding = 'utf-8') as f:\n",
    "        stop_words = f.readlines()\n",
    "        stop_words = [w.strip() for w in stop_words]\n",
    "    final_words = [word for word in alphabetic_words if word not in stop_words]\n",
    "    print('Fin de la normalización...')\n",
    "    return final_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32872f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematize(text):\n",
    "    input_f = open('lemmas.pkl', 'rb')\n",
    "    lemmas = load(input_f)\n",
    "    input_f.close()\n",
    "    \n",
    "    lemmatized_text = []\n",
    "    for word in text:\n",
    "        if word in lemmas.keys():\n",
    "            lemmatized_text.append(lemmas[word])\n",
    "        else:\n",
    "            lemmatized_text.append(word)\n",
    "    print('Fin de la lematización...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5454df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de la normalización...\n",
      "Algunas palabras despues de la normalización: \n",
      "['emodhtm', 'httpwwwexcelsiorcommxarthtml', 'excelsior', 'editorial', 'martes', 'abril', 'monstruosa', 'diferencia', 'colosistas', 'colosismo', 'luis', 'gutierrez', 'gonzalez', 'luis', 'gutiérrez', 'sotomayor', 'federico', 'arreola', 'colosistas', 'cabales', 'según', 'dijo', 'amigo', 'luis', 'donaldo', 'ciertamente', 'nombre', 'circunstancias', 'luis', 'donaldo', 'colosio', 'llenado', 'insistentemente', 'volúmenes', 'espacios', 'medios', 'comunicación', 'renovada', 'actualidad', 'padecido', 'frenético', 'vaivén', 'ficciones', 'judiciales', 'políticas', 'integran', 'disgregan', 'metafísicas', 'metafísicas', 'aún', 'luis', 'donaldo', 'desprende', 'envuelve', 'lado', 'espejo', 'dos', 'años', 'eternos', 'insolvencias', 'dale', 'dale', 'fantasía', 'magia', 'dónde', 'quedó', 'bolita', 'traído', 'pueblo', 'hastío', 'cansancio', 'inminencia', 'percibe', 'váyanse', 'diablo', 'quórum', 'nacional', 'veía', 'decidido', 'instalar', 'sécula', 'seculórum', 'demandas', 'justicia', 'segundo', 'aniversario', 'asesinato', 'colosismo', 'astroso', 'luto', 'protagónico', 'intentado', 'empapar', 'drama', 'colosista', 'espesas', 'negras', 'lágrimas', 'llorona', 'profesional', 'velorio', 'antigüita', 'diciéndose', 'heredero', 'ideas', 'derechos', 'supuesto', 'paradigma', 'trampa', 'tendió', 'esotérico', 'colosismo', 'presidente', 'zedillo', 'ponce', 'león', 'amigo', 'líder', 'mandatario', 'dedica', 'culto', 'seguimiento', 'espirituales', 'dándole', 'satisfacción', 'compromisos', 'políticos', 'aquel', 'contrajo', 'actitud', 'moral', 'propició', 'trampa', 'fulano', 'zutano', 'dijeron', 'discípulos', 'hermanos', 'compañeros', 'lucha', 'asesores', 'caído', 'veras', 'hicieron', 'lado', 'vieron', 'cargar', 'don', 'ernesto', 'tropel', 'búfalos', 'llora', 'mama', 'colosistas', 'supieron', 'quisieron', 'vergüenza', 'ser', 'confundidos', 'pegarse', 'ubre', 'mal', 'hicieron', 'colosismo', 'repartió', 'mercedes', 'presidenciales', 'parteaguas', 'brecha', 'insondable', 'separando', 'colosistas', 'colosismo', 'bandos', 'luis', 'donaldo', 'llamaba', 'dijo', 'nombres', 'respectivos', 'cabales', 'oportunistas', 'efeméride', 'dolorosa', 'colosismo', 'intentó', 'constituirse', 'dogma', 'doctrina', 'credo', 'político', 'allá', 'magdalena', 'leyendo', 'lumpen', 'histriónico', 'viendo', 'protagonismos', 'don', 'luis']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    words = normalize()\n",
    "    print(f'Algunas palabras despues de la normalización: \\n{words[:200]}')\n",
    "except Exception as e:\n",
    "    print('Ocurrió el siguiente error: ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e6f8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 2] No such file or directory: 'lemmas.pkl'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    new_words = lematize(words)\n",
    "    print(f'Algunas palabras despues de la normalización: \\n{words[:200]}')\n",
    "except Exception as e:\n",
    "    print('Error:', e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
